from sklearn.datasets import fetch_california_housing
import sklearn as sk
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.datasets import load_boston
import lightgbm as ltb

df = pd.read_csv("data.csv")

boston = load_boston()

house_price_dataset = fetch_california_housing()
house_price_panda = fetch_california_housing(as_frame =True)

X = df.drop(['index', 'title', 'sqft', 'type', 'bedrooms', 'final_price','parking', 'description', 'mls', 'full_link', 'full_address', 'final_price_transformed', 'city_district', 'final_price_log'], axis=1)
Y = df['final_price']

poly = PolynomialFeatures(degree=1, include_bias=False)
scaler_linear = StandardScaler()

x_train, x_2, y_train, y_2 = train_test_split(X, Y, test_size=0.4, random_state = 3)
x_cv, x_test, y_cv, y_test = train_test_split(x_2, y_2, test_size=0.5, random_state = 3)

model = XGBRegressor()
#learning_rate=0.14, max_depth=6, n_estimators=92)

model.fit(x_train, y_train)

train_result = model.predict(x_train)

score_1 = metrics.r2_score(y_train, train_result)
score_2 = metrics.mean_absolute_error(y_train, train_result)

print(f"Round Squared Error: {score_1}")
print(f"Mean Absolute Error: {score_2}")

cv_result = model.predict(x_cv)

score_1 = metrics.r2_score(y_cv, cv_result)
score_2 = metrics.mean_absolute_error(y_cv, cv_result)

print(f"Round Squared Error: {score_1}")
print(f"Mean Absolute Error: {score_2}")

test_result = model.predict(x_test)

score_1 = metrics.r2_score(y_test, test_result)
score_2 = metrics.mean_absolute_error(y_test, test_result)

print(f"Round Squared Error: {score_1}")
print(f"Mean Absolute Error: {score_2}")

plt.scatter(y_test, test_result)
plt.xlabel("Actual Prices")
plt.ylabel("Predictid Price")
plt.title("Actual Price vs Predicted Price")
plt.axis('square')
plt.show()
